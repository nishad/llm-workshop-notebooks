{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e705ed-4c75-403c-87fd-c90119b6a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a3e6e-9215-401c-8844-a31e9ad2dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import hashlib\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf80e35-9f34-4900-9f50-ae1e2750c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = chroma_client.create_collection(name=\"rag_documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614eb1f-8529-4700-841a-cbd87870014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash_id(document):\n",
    "    \"\"\"\n",
    "    Generates a hash-based ID for a given document string.\n",
    "\n",
    "    Args:\n",
    "        document (str): The document string for which the ID is generated.\n",
    "\n",
    "    Returns:\n",
    "        str: A hash-based ID for the document.\n",
    "    \"\"\"\n",
    "    # Use SHA-256 hash function for generating a consistent ID\n",
    "    return hashlib.sha256(document.encode('utf-8')).hexdigest()\n",
    "\n",
    "def load_documents_from_text_file(file_path, collection):\n",
    "    \"\"\"\n",
    "    Loads documents from a text file, assigns a hash-based ID to each document, \n",
    "    and adds them to a collection.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file containing documents (one per line).\n",
    "        collection (object): The collection object to which the documents and IDs will be added.\n",
    "\n",
    "    Functionality:\n",
    "        - Reads a text file line by line.\n",
    "        - Strips whitespace from each line and skips empty lines.\n",
    "        - Generates a hash-based ID for each document.\n",
    "        - Adds the documents and IDs to the collection using `collection.upsert()`.\n",
    "\n",
    "    Example Usage:\n",
    "        collection = some_vector_database.collection(\"my_collection\")\n",
    "        load_documents_from_text_file(\"trivia.txt\", collection)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open and read the text file line by line\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Process each line to strip whitespace and remove empty entries\n",
    "        documents = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "        # Generate hash-based IDs for each document\n",
    "        ids = [generate_hash_id(doc) for doc in documents]\n",
    "\n",
    "        # Add the documents and IDs to the collection\n",
    "        collection.upsert(documents=documents, ids=ids)\n",
    "\n",
    "        print(f\"Successfully added {len(documents)} documents to the collection.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54d3a8-ac10-4d4b-becc-4c1463464292",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_documents_from_text_file(\"trivia.txt\", documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6eec1d-df8f-4bee-8f41-53423dbca812",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = documents.query(\n",
    "    query_texts=[\"university sport\"], # Chroma will embed this for you\n",
    "    n_results=4 # how many results to return\n",
    ")\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587d110-5682-4906-bdc1-363d23a3fbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fa9ad-aab7-4572-a883-a574e7b72f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "# Make sure that you have pulled the embedding model nomic-embed-text\n",
    "ollama_embedding = embedding_functions.OllamaEmbeddingFunction(\n",
    "    url=\"http://localhost:11434/api/embeddings\",\n",
    "    model_name=\"nomic-embed-text\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b5c66-c452-4824-86f4-f8a31fbca8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ollama_embedding([\"This is a sample text to try ollama embedding at the workshop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed346646-53b8-488d-8995-e346f793e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb641410-4426-455a-9528-9189026c7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_client = chromadb.PersistentClient(path=\"./vector-db/made-with-cc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6dc567-c441-4117-905c-42b7fa70882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line_number_id(index):\n",
    "    \"\"\"\n",
    "    Generates an ID based on the line number.\n",
    "\n",
    "    Args:\n",
    "        index (int): The zero-based index of the line in the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The line number ID as a string (1-based index).\n",
    "    \"\"\"\n",
    "    return str(index + 1)\n",
    "\n",
    "def get_embedding_for_document(document):\n",
    "    \"\"\"\n",
    "    Generates an embedding for a given document using the `ollama_embedding` function.\n",
    "\n",
    "    Args:\n",
    "        document (str): The document text.\n",
    "\n",
    "    Returns:\n",
    "        list: The embedding for the document.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace this with the actual call to the ollama embedding API\n",
    "        return ollama_embedding([document])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding for document: {document[:30]}... Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_documents_with_line_ids_and_embeddings(file_path, collection):\n",
    "    \"\"\"\n",
    "    Loads documents from a text file, assigns a line number as the ID to each document,\n",
    "    generates embeddings for each document, and adds them to a collection.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file containing documents (one per line).\n",
    "        collection (object): The collection object to which the documents, IDs, and embeddings will be added.\n",
    "\n",
    "    Functionality:\n",
    "        - Reads a text file line by line.\n",
    "        - Strips whitespace from each line and skips empty lines.\n",
    "        - Generates a line number ID for each document.\n",
    "        - Generates embeddings for each document sequentially.\n",
    "        - Adds the documents, IDs, and embeddings to the collection using `collection.upsert()`.\n",
    "\n",
    "    Example Usage:\n",
    "        collection = some_vector_database.collection(\"my_collection\")\n",
    "        load_documents_with_line_ids_and_embeddings(\"trivia.txt\", collection)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open and read the text file line by line\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Process each line to strip whitespace and remove empty entries\n",
    "        documents = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "        # Generate line number IDs for each document\n",
    "        ids = [generate_line_number_id(i) for i in range(len(documents))]\n",
    "\n",
    "        # Generate embeddings sequentially\n",
    "        embeddings = []\n",
    "        for doc in documents:\n",
    "            embedding = get_embedding_for_document(doc)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "            else:\n",
    "                embeddings.append([])  # Append an empty list for documents that fail\n",
    "\n",
    "        # Add the documents, IDs, and embeddings to the collection\n",
    "        collection.upsert(documents=documents, ids=ids, embeddings=embeddings)\n",
    "\n",
    "        print(f\"Successfully added {len(documents)} documents with embeddings to the collection.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277eb795-443c-4d9a-96c6-6e2fdc0c79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_collection = cc_client.create_collection(name=\"made-with-cc\")\n",
    "cc_collection = cc_client.get_collection(name=\"made-with-cc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d2218-1485-4b0c-9050-76ab0f62e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_documents_with_line_ids_and_embeddings(\"made-with-cc.txt\", cc_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea685bc-9c09-4f4d-b1cb-f2fff23968b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cc_collection.query(\n",
    "    query_embeddings=ollama_embedding([\"What are the best examples for sharing economy use-cases?\"]),\n",
    "    n_results=10 # how many results to return\n",
    ")\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90973999-8c4e-4f0e-885e-93ac9bfa4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "stream = chat(\n",
    "    model='llama3.2:3b',\n",
    "    messages=[{'role': 'user', 'content': 'What are the best examples for sharing economy use-cases?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d02b4-4722-41d3-ab88-f841c535003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the best examples for sharing economy use-cases?\"\n",
    "updated_query = f\"{query} - Answer that question using the following text as a resource: {results[\"documents\"]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b27819-f496-43b6-8112-b8189f18879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = chat(\n",
    "    model='llama3.2:3b',\n",
    "    messages=[{'role': 'user', 'content': updated_query}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1d28d-a9de-4308-a336-4693a6c351c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
